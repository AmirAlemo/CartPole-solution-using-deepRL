{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RLProject.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM+qhPoOltv9ZIBNySiBZ8E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmirAlemo/CartPole-solution-using-deepRL/blob/main/RLProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "#required Python dependencies\n",
        "pip install pyvirtualdisplay PyOpenGL PyOpenGL-accelerate\n",
        "#required system dependencies\n",
        "apt-get install -y xvfb x11-utils"
      ],
      "metadata": {
        "id": "itOV8J3-pbiC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gym[classic_control]==0.21.*"
      ],
      "metadata": {
        "id": "0Ql4YdkHsQFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import collections\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import gym\n",
        "from gym import logger as gymlogger\n",
        "from gym.wrappers import Monitor\n",
        "import glob\n",
        "import io\n",
        "import base64\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from IPython.display import HTML\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "\n",
        "#Hyperparameters\n",
        "\n",
        "learning_rate = 0.0005\n",
        "gamma = 0.98\n",
        "buffer_limit = 50000\n",
        "batch_size = 32\n",
        "video_every = 25\n",
        "print_every = 5\n",
        "\n",
        "\n",
        "class ReplayBuffer():#Experience Buffer\n",
        "\n",
        "   def __init__(self):\n",
        "     self.buffer = collections.deque(maxlen=buffer_limit) #We set an upper limit for our running experience memory(deque) as buffer_limit\n",
        "\n",
        "\n",
        "   def put(self,transition):#Adding transition as Tuple into our experience buffer\n",
        "     self.buffer.append(transition)\n",
        "\n",
        "\n",
        "   def sample(self, n):#Random generated transitions\n",
        "       mini_batch = random.sample(self.buffer, n)\n",
        "       s_lst, a_lst, r_lst, s_prime_lst, done_mask_lst = [], [], [], [], []\n",
        "\n",
        "       for  transition in mini_batch:\n",
        "         s, a, r, s_prime, done_mask = transition\n",
        "         s_lst.append(s)\n",
        "         a_lst.append([a])\n",
        "         r_lst.append([r])\n",
        "         s_prime_lst.append(s_prime)\n",
        "         done_mask_lst.append([done_mask])\n",
        "\n",
        "         return torch.tensor(s_lst, dtype=torch.float), torch.tensor(a_lst), \\\n",
        "         torch.tensor(r_lst), torch.tensor(s_prime_lst, dtype=torch.float), \\\n",
        "         torch.tensor(done_mask_lst)\n",
        "\n",
        "   def size(self):#Returns the length of our memory deque\n",
        "    return len(self.buffer)\n",
        "\n",
        "class QNetwork(nn.Module):\n",
        "\n",
        " def __init__(self, insize, outsize): #Defining a fully connected 3-layer neural network\n",
        "  super(QNetwork, self).__init__()\n",
        "  self.fc1 = nn.Linear(insize, 256)\n",
        "  self.fc2 = nn.Linear(256, 84)\n",
        "  self.fc3 = nn.Linear(84, outsize)\n",
        "\n",
        "\n",
        " def forward(self, x):#Producing ALL of the action scores in parallel\n",
        "      x = x.view(x.size(0), -1)\n",
        "      x = F.relu(self.fc1(x))\n",
        "      x = F.relu(self.fc2(x))\n",
        "      x = self.fc3(x)\n",
        "      return x\n",
        "\n",
        "\n",
        " def sample_action(self, obs, epsilon):#Producing a random action every once in a while!\n",
        "      out = self.forward(obs)\n",
        "      coin = random.random()\n",
        "      if coin < epsilon:\n",
        "        return random.randint(0,1)\n",
        "      else:\n",
        "          return out.argmax().item()#Max over all of our action scores\n",
        "\n",
        "\n",
        "def train(q, q_target, memory, optimizer):#Training loop to run 10 times per iteration\n",
        "      for i in range(10):\n",
        "        s, a, r, s_prime, done_mask = memory.sample(batch_size)\n",
        "\n",
        "        q_out = q(s)\n",
        "        q_a = q_out.gather(1, a)\n",
        "        max_q_prime = q_target(s_prime).max(1)[0].unsqueeze(1)\n",
        "        target = r + gamma*max_q_prime*done_mask\n",
        "        loss = F.smooth_l1_loss(q_a, target)\n",
        "         #optimizer\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "id": "6MHe2jgAhhRq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyvirtualdisplay import Display#Display buffer\n",
        "display = Display(visible=False, size=(1400,900))\n",
        "display.start()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLUVH77YrZaO",
        "outputId": "062c238b-ba0b-4dff-f899-b807d663f67c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x7f27e2498310>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!echo $DISPLAY#Test if Display is available"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbVr4d4OrJcs",
        "outputId": "bef99e26-0eec-4e9c-beba-0d93654aa032"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ":0#Test if Display is available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Setting up the training environment and recording a video from the training sesseion every 5 episodes\n",
        "env = gym.make('CartPole-v0')\n",
        "env = gym.wrappers.Monitor(env, \"/video\", video_callable=lambda episode_id: (episode_id%video_every)==0, force = True)\n"
      ],
      "metadata": {
        "id": "48t40m5dunPn"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env.reset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_PMHI8-KMcc",
        "outputId": "53f99fcb-77eb-4e93-a55d-130576cad9c0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.01392667, -0.02733683,  0.04163995, -0.03474056], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(env.render(mode='rgb_array'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "aYUY75K9uBFZ",
        "outputId": "d93d89f8-7481-4743-9c5f-b39c506e02fd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f3ba33391d0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Train!\n",
        "seed = 742\n",
        "torch.manual_seed(seed)\n",
        "env.seed(seed)\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "env.action_space.seed(seed)\n",
        "\n",
        "\n",
        "q = QNetwork(np.array(env.observation_space.shape).prod(), env.action_space.n)\n",
        "q_target = QNetwork(np.array(env.observation_space.shape).prod(), env.action_space.n)\n",
        "q_target.load_state_dict(q.state_dict())\n",
        "memory = ReplayBuffer()\n",
        "\n",
        "\n",
        "score = 0.0\n",
        "marking = []\n",
        "optimizer = optim.Adam(q.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "for n_episode in range(3001):\n",
        "   epsilon = max(0.01, 0.08 - 0.01*(n_episode/200))#Linear annealing from 8% to 1%\n",
        "   s = env.reset()\n",
        "   done = False\n",
        "   score = 0.0\n",
        "\n",
        "   while True:\n",
        "\n",
        "     a = q.sample_action(torch.from_numpy(s).float().unsqueeze(0), epsilon)\n",
        "     s_prime, r, done, info = env.step(a)\n",
        "     done_mask = 0.0 if done else 1.0\n",
        "     memory.put((s, a, r/200, s_prime, done_mask))#Generating samples (state, action, reward, future next step, check if done) and plugging them into memory\n",
        "     s = s_prime\n",
        "\n",
        "     score += r#Piling on the rewards as we go forward\n",
        "     if done:\n",
        "       break\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "   if memory.size()>2000:#Size is selected 2000 just to even the distribution\n",
        "       train(q, q_target, memory, optimizer)\n",
        "\n",
        "\n",
        "   marking.append(score)\n",
        "   if n_episode%100 == 0:\n",
        "      print(\"marking, episode: {}, score: {:.1f}, mean_score: {:.2f}, std_score: {:.2f}\".format(\n",
        "          n_episode, score, np.array(marking).mean(), np.array(marking).std()))\n",
        "      marking = []\n",
        "\n",
        "\n",
        "   if n_episode%print_every == 0 and n_episode != 0:\n",
        "      q_target.load_state_dict(q.state_dict())\n",
        "      print(\"episode: {}, score :{:.1f}, epsilon: {:.2f}\".format(n_episode, score, epsilon))"
      ],
      "metadata": {
        "id": "-Chwt_yhMLHp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}